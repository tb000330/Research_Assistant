{"cells":[{"cell_type":"code","execution_count":229,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6176,"status":"ok","timestamp":1658910703864,"user":{"displayName":"김다은","userId":"16190703000834159129"},"user_tz":-540},"id":"_Iq30ierSqUj","outputId":"ba3a177c-c6ab-44ef-ce40-28d51ec0588a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[""],"metadata":{"id":"49psws_rxH9y","executionInfo":{"status":"ok","timestamp":1658913804913,"user_tz":-540,"elapsed":6,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":232,"outputs":[]},{"cell_type":"code","execution_count":231,"metadata":{"id":"qqwM6Qd90aHt","executionInfo":{"status":"ok","timestamp":1658912389146,"user_tz":-540,"elapsed":13,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"outputs":[],"source":["import numpy as np #대수학\n","import pandas as pd #전처리\n","\n","import seaborn as sns #시각화\n","from matplotlib.patches import Patch\n","from matplotlib import pyplot as plt\n","\n","from tensorflow.keras.models import load_model\n","\n","plt.rcParams.update({'figure.max_open_warning': 0})\n","plt.style.use('fivethirtyeight')\n","cmap_data = plt.cm.Paired\n","cmap_cv = plt.cm.coolwarm\n","\n","import warnings\n","%matplotlib inline\n","\n","import configparser\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import re\n","import time\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import datetime as dt\n","\n","import os # 경로\n","\n","import numpy as np\n","import sys\n","import random as rn\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional\n","\n","import configparser\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import SimpleRNN\n","from keras.layers import Dropout\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler"]},{"cell_type":"code","source":["pip install AutoReg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w51esET3tJQy","executionInfo":{"status":"ok","timestamp":1658909471236,"user_tz":-540,"elapsed":3142,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"350f8145-dd03-4008-8544-bff94ae52aea"},"execution_count":211,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: AutoReg in /usr/local/lib/python3.7/dist-packages (1.1)\n"]}]},{"cell_type":"code","source":["# import required libraries\n","\n","import xgboost as xgb\n","import pandas as pd\n","import os\n","import numpy as np\n","import requests\n","import datetime\n","import statsmodels.api as sm\n","from statsmodels.tsa.x13 import x13_arima_analysis, x13_arima_select_order\n","# from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n","import copy\n","import IPython\n","\n","\n","\n","import random as rn\n","import numpy as np #대수학\n","import pandas as pd #전처리\n","import seaborn as sns #시각화\n","from matplotlib.patches import Patch\n","from matplotlib import pyplot as plt\n","\n","plt.rcParams.update({'figure.max_open_warning': 0})\n","plt.style.use('fivethirtyeight')\n","cmap_data = plt.cm.Paired\n","cmap_cv = plt.cm.coolwarm\n","\n","import warnings\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","\n","import configparser\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n","\n","import re\n","import time\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import datetime as dt\n","\n","import os # 경로\n","\n","import numpy as np\n","import sys\n","import random \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, GRU\n","\n","import configparser\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import SimpleRNN\n","from keras.layers import Dropout\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from statsmodels.multivariate.pca import PCA"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"K_5IpOdzkBuz","executionInfo":{"status":"error","timestamp":1658909471236,"user_tz":-540,"elapsed":9,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"b97711a6-bd39-4b4a-b93a-335978604765"},"execution_count":212,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-212-0a542b06f303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mx13_arima_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx13_arima_select_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mar_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoReg\u001b[0m\u001b[0;31m#, ar_select_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoReg' from 'statsmodels.tsa.ar_model' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/ar_model.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[""],"metadata":{"id":"_vg3cPLStP7V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sets the working directory: the default directory is the one in which the variable list file is stored.\n","\n","cwd = os.getcwd()\n","os.chdir(cwd)"],"metadata":{"id":"1lfIMgMokTXt","executionInfo":{"status":"ok","timestamp":1658907090076,"user_tz":-540,"elapsed":534,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["# The function receives a response object when given `url'\n","\n","def get_request_url(url):\n","    \n","    try:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            print (\"[%s]: Url Request Success\" % datetime.datetime.now())\n","            return response.json()\n","        \n","    except Exception as e:\n","        print(e)\n","        print(\"[%s]: Error for URL : %s\" % (datetime.datetime.now(), url))\n","        return None"],"metadata":{"id":"nXxohBsHkTQi","executionInfo":{"status":"ok","timestamp":1658907099550,"user_tz":-540,"elapsed":540,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["# a function that collects a quarterly GDP growth series and future gdp growth\n","\n","def get_actual_gdp_growth(key, start, end):\n","        \n","    stat_code = '200Y002'\n","    item_code1 = '10111'    \n","    \n","    url = f'http://ecos.bok.or.kr/api/StatisticSearch/{key}/json/kr/1/1000/{stat_code}/Q/{start}/{end}/{item_code1}'\n","    \n","    retData = get_request_url(url)\n","    \n","    if (retData == None):\n","        print(\"there is no data\")\n","        return None\n","    else:\n","        \n","        data = retData['StatisticSearch']\n","        data = pd.DataFrame(data['row'])\n","        data = data[['DATA_VALUE', 'TIME']]        \n","        data.columns = ['GDP_GROWTH', 'TIME']\n","        \n","        data['DATE'] = pd.to_datetime(data['TIME']).dt.to_period('Q')\n","        data = data[['GDP_GROWTH', 'DATE']]    \n","        data = data.set_index('DATE')\n","\n","        size = data.shape[0]\n","        \n","        gdp_series = data.resample('1M', convention = 'start').pad() \n","        gdp_series.index = pd.PeriodIndex(gdp_series.index, freq = 'M')\n","        \n","        return gdp_series"],"metadata":{"id":"ZRchaNqskTJe","executionInfo":{"status":"ok","timestamp":1658907106330,"user_tz":-540,"elapsed":545,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["\n","# a function which collects the individual feature variable\n","\n","def get_individual_var(access_key, start, end, stat_code, item_code1, item_code2, freq):\n","    \n","    key = access_key\n","    \n","    if item_code2 == 0:\n","        url = f'http://ecos.bok.or.kr/api/StatisticSearch/{key}/json/kr/1/1000/{stat_code}/{freq}/{start}/{end}/{item_code1}'\n","    else:\n","        url = f'http://ecos.bok.or.kr/api/StatisticSearch/{key}/json/kr/1/1000/{stat_code}/{freq}/{start}/{end}/{item_code1}/{item_code2}'\n","    \n","    retData = get_request_url(url)\n","    \n","    if (retData == None):\n","        print(\"there is no data\")\n","        return None\n","    \n","    else:\n","        data = retData['StatisticSearch']\n","        data = pd.DataFrame(data['row'])\n","        return data "],"metadata":{"id":"Jxt66jiSkS44","executionInfo":{"status":"ok","timestamp":1658907124365,"user_tz":-540,"elapsed":567,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["\n","# a function which obtains all monthly variables with additional information (lag, diff, group information)\n","# `start' and 'end' must be year-month format\n","# 'ispadding' refers to whether fill missing values for quarterly variable\n","\n","def get_raw_data(key, start, end, IsPad):\n","    \n","    os.chdir(\"/content/drive/MyDrive/Colab Notebooks/gdp_re\") '@'\n","    var_list = pd.read_csv('VarList_20220703_NABO.csv')\n","    num_var = var_list.shape[0]\n","    varname_set = var_list['VarName'].to_list()\n","    \n","    \n","    # a dictionary which contains the variable's lag structure, seasonality, difference\n","    \n","    dic = {}\n","    \n","    for i, j in zip(varname_set, range(len(varname_set))):\n","        dic[i] = {'LAG': var_list.iloc[j]['LAG'], 'DIFF': var_list.iloc[j]['DIFF'],\n","                  'ISA': var_list.iloc[j]['ISA'], 'GROUP': var_list.iloc[j]['GROUP']}\n","    \n","    \n","    \n","    # initialize data set: the set which consists of 1 variable\n","    stat_code = var_list.iloc[0]['STAT_CODE']\n","    item_code1 = var_list.iloc[0]['ITEM_CODE1']\n","    item_code2 = var_list.iloc[0]['ITEM_CODE2']\n","    lags = var_list.iloc[0]['LAG']\n","    freq = var_list.iloc[0]['FREQ']\n","    \n","    \n","    start_m = pd.to_datetime(start, format ='%Y%m')\n","    end_m = pd.to_datetime(end, format ='%Y%m')\n","          \n","    pi = pd.period_range(start_m, end_m, freq = \"Q\")\n","    period_list = list(pi.astype(str))\n","    \n","    start_q = period_list[0]\n","    end_q = period_list[-1]\n","    \n","    if freq == 'Q':\n","        data = get_individual_var(key, start_q, end_q, stat_code, item_code1, item_code2, freq) \n","    else:\n","        data = get_individual_var(key, start, end, stat_code, item_code1, item_code2, freq) \n","    \n","    data = data[['DATA_VALUE', 'TIME']]        \n","    data.columns = [varname_set[0], 'TIME']\n","    \n","    \n","    if freq == 'M':\n","        data['DATE'] = pd.to_datetime(data['TIME'], format = '%Y%m')\n","        data = data[[varname_set[0], 'DATE']]    \n","        data = data.set_index('DATE')\n","        data.index = pd.PeriodIndex(data.index, freq = 'M')\n","    \n","    else:\n","        data['DATE'] = pd.to_datetime(data['TIME']).dt.to_period('Q')\n","        data = data[[varname_set[0], 'DATE']]    \n","        data = data.set_index('DATE')\n","        \n","        if IsPad == 1:\n","                data = data.resample('1M', convention = 'start').pad()\n","        else:\n","                data = data.resample('1M', convention = 'end').last()\n","        \n","        data.index = pd.PeriodIndex(data.index, freq = 'M')\n","    \n","    \n","    # collect each variable through for-loop\n","    \n","    for i in range(1, num_var):\n","        \n","        stat_code = var_list.iloc[i]['STAT_CODE']\n","        item_code1 = var_list.iloc[i]['ITEM_CODE1']\n","        item_code2 = var_list.iloc[i]['ITEM_CODE2']\n","        freq = var_list.iloc[i]['FREQ']\n","        \n","        if freq == 'Q':\n","            var = get_individual_var(key, start_q, end_q, stat_code, item_code1, item_code2, freq) # var denotes the individual variable\n","        else:\n","            var = get_individual_var(key, start, end, stat_code, item_code1, item_code2, freq) \n","            \n","        var = var[['DATA_VALUE', 'TIME']]        \n","        var.columns = [var_list.iloc[i]['VarName'], 'TIME']\n","  \n","        if freq == 'M':\n","            var['DATE'] = pd.to_datetime(var['TIME'], format = '%Y%m')\n","            var = var[[varname_set[i], 'DATE']]    \n","            var = var.set_index('DATE')\n","            var.index = pd.PeriodIndex(var.index, freq = 'M')\n","    \n","        else:\n","            var['DATE'] = pd.to_datetime(var['TIME']).dt.to_period('Q')\n","            var = var[[varname_set[i], 'DATE']]    \n","            var = var.set_index('DATE')\n","            \n","            if IsPad == 1:\n","                var = var.resample('1M', convention = 'start').pad()\n","            else:\n","                var = var.resample('1M', convention = 'end').last()\n","            \n","            var.index = pd.PeriodIndex(var.index, freq = 'M')\n","    \n","        data = data.join(var)\n","        \n","    return data, dic"],"metadata":{"id":"NQ9BAYaXkj05","executionInfo":{"status":"ok","timestamp":1658907295018,"user_tz":-540,"elapsed":728,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["raw_data, dic = get_raw_data('7MJBDXDXI03KBLP71JFE', '200001', '202112', 0)\n","raw_data.to_csv('raw_data.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_GrgwMCkSjp","executionInfo":{"status":"ok","timestamp":1658907352961,"user_tz":-540,"elapsed":55532,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"5a0bcc88-d5bb-4126-bcb4-dac8176d493d"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-07-27 07:34:59.367315]: Url Request Success\n","[2022-07-27 07:35:00.858089]: Url Request Success\n","[2022-07-27 07:35:02.720892]: Url Request Success\n","[2022-07-27 07:35:04.303931]: Url Request Success\n","[2022-07-27 07:35:05.752945]: Url Request Success\n","[2022-07-27 07:35:07.191817]: Url Request Success\n","[2022-07-27 07:35:08.626312]: Url Request Success\n","[2022-07-27 07:35:10.176612]: Url Request Success\n","[2022-07-27 07:35:11.664761]: Url Request Success\n","[2022-07-27 07:35:13.050435]: Url Request Success\n","[2022-07-27 07:35:14.604293]: Url Request Success\n","[2022-07-27 07:35:15.969627]: Url Request Success\n","[2022-07-27 07:35:17.441351]: Url Request Success\n","[2022-07-27 07:35:18.790036]: Url Request Success\n","[2022-07-27 07:35:20.183795]: Url Request Success\n","[2022-07-27 07:35:21.575681]: Url Request Success\n","[2022-07-27 07:35:22.931308]: Url Request Success\n","[2022-07-27 07:35:24.344102]: Url Request Success\n","[2022-07-27 07:35:26.551344]: Url Request Success\n","[2022-07-27 07:35:28.017078]: Url Request Success\n","[2022-07-27 07:35:29.640828]: Url Request Success\n","[2022-07-27 07:35:31.154558]: Url Request Success\n","[2022-07-27 07:35:32.528403]: Url Request Success\n","[2022-07-27 07:35:33.953600]: Url Request Success\n","[2022-07-27 07:35:35.351782]: Url Request Success\n","[2022-07-27 07:35:36.779701]: Url Request Success\n","[2022-07-27 07:35:38.230094]: Url Request Success\n","[2022-07-27 07:35:39.641321]: Url Request Success\n","[2022-07-27 07:35:41.036776]: Url Request Success\n","[2022-07-27 07:35:42.412740]: Url Request Success\n","[2022-07-27 07:35:43.809746]: Url Request Success\n","[2022-07-27 07:35:45.149187]: Url Request Success\n","[2022-07-27 07:35:46.506956]: Url Request Success\n","[2022-07-27 07:35:47.862645]: Url Request Success\n","[2022-07-27 07:35:49.120275]: Url Request Success\n","[2022-07-27 07:35:50.516598]: Url Request Success\n","[2022-07-27 07:35:51.864061]: Url Request Success\n"]}]},{"cell_type":"code","source":["\n","# a fuction which returns a vintage data and dictionary of other additional information\n","\n","def get_vintage_data(start_vintage, end_vintage):\n"," \n","    os.chdir(\"/content/drive/MyDrive/Colab Notebooks/gdp_re\")\n","    var_list = pd.read_csv('VarList_20220703_NABO.csv')\n","    varname_set = var_list['VarName'].to_list()\n","    \n","    # a dictionary which contains the variable's lag structure, seasonality, difference\n","    \n","    dic = {}\n","    \n","    for i, j in zip(varname_set, range(len(varname_set))):\n","        dic[i] = {'LAG': var_list.iloc[j]['LAG'], 'DIFF': var_list.iloc[j]['DIFF'],\n","                  'ISA': var_list.iloc[j]['ISA'], 'GROUP': var_list.iloc[j]['GROUP'],\n","                  'FREQ': var_list.iloc[j]['FREQ']}\n","    \n","    \n","    # reading the raw data and reflelct the vintage point\n","    \n","    raw_data =pd.read_csv('raw_data.csv')\n","    raw_data = raw_data.set_index('DATE')\n","    raw_data.index = pd.PeriodIndex(raw_data.index, freq = 'M')\n","    data = raw_data[(raw_data.index >= start_vintage) & (raw_data.index <= end_vintage)]\n","    \n","    # setting the vintage date points\n","    \n","    start_v = pd.to_datetime(start_vintage, format ='%Y%m')\n","    end_v = pd.to_datetime(end_vintage, format ='%Y%m')\n","    \n","    \n","    # get the month of the end_v\n","    current_month = end_v.month\n","    \n","    first_month = [1, 4, 7, 10]\n","    middle_month = [2, 5, 8, 11]\n","    \n","    \n","    # sets the current state of forecasting point either 초월, 중월, 말월\n","    \n","    state = 2\n","    \n","    if current_month in first_month:\n","        state = 0\n","    if current_month in middle_month:\n","        state = 1\n","    \n","\n","    size = data.shape[0]\n","    data = data.astype(float)\n","   \n","    for i in varname_set:               \n","                    \n","                    num_lag = dic[i]['LAG'] \n","                    var_freq = dic[i]['FREQ']\n","                    \n","                    if var_freq == 'M':\n","                        \n","                        if num_lag == 1:\n","                            \n","                            data[i][-1] = np.nan\n","                            \n","                        if num_lag== 2:\n","                            \n","                            for k in range(num_lag):\n","                                data[i][size - k - 1] = np.nan\n","                    \n","                    if var_freq == 'Q': # quarterly variable's lag is equal to 2 month\n","                        \n","                        \n","                        if state == 2:\n","                            \n","                            for k in range(num_lag):\n","                                data[i][size - k-1] = np.nan\n","                        else:\n","                            for k in range(num_lag*2):\n","                                data[i][size - k - 1] = np.nan\n","                    \n","                        \n","#                         # below is for padded data\n","                        \n","#                         if state == 2:\n","                            \n","#                             #for k in range(num_lag):\n","#                             for k in range(num_lag + 1): # for padded data      \n","#                                 data[i][size - k-1] = np.nan\n","                        \n","#                         elif state == 1:\n","#                             #for k in range(num_lag*2):\n","#                             for k in range(num_lag*2 + 1): # for padded data   \n","#                                 data[i][size - k - 1] = np.nan\n","                                \n","#                         else:\n","#                             #for k in range(num_lag*2):\n","#                             for k in range(num_lag*2 ): # for padded data   \n","#                                 data[i][size - k - 1] = np.nan        \n","                    \n","    data.index = pd.PeriodIndex(data.index, freq = 'M')\n","    \n","    return data, dic"],"metadata":{"id":"RU_mK6sOkSYi","executionInfo":{"status":"ok","timestamp":1658908183222,"user_tz":-540,"elapsed":604,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["# function that transforms into differenced series and seasonally-adjusted series\n","\n","def transform(vintage_data, dic):\n","    \n","    # make a deep copy\n","    \n","    data = copy.deepcopy(vintage_data)\n","    \n","    # the set of variable names\n","    col_names = data.columns\n","\n","    for var in col_names:\n","        \n","        # log difference or just difference\n","        if dic[var]['DIFF'] == 1:\n","            data[var] = np.log(data[var].astype(float)).diff()\n","        \n","        elif dic[var]['DIFF'] == 2:\n","            data[var] = data[var].astype(float).diff()\n","        \n","        else:\n","            pass\n","\n","        \n","        # seasonal adjustment\n","        if dic[var]['ISA'] == 0:\n","            \n","            nan_check = data[var].isnull() \n","            idx = data[var].index[nan_check == False]\n","            \n","            # checkpoints for where not-NaN value start and end in the time series\n","            start = np.where(data.index == idx[0])[0][0]\n","            end = np.where(data.index == idx[-1])[0][0]\n","\n","            # generate seasnoally-adjusted variable\n","            \n","            orig_series = data[var].iloc[start:end+1]\n","            \n","            X13PATH = os.chdir(\"/content/drive/MyDrive/Colab Notebooks/gdp_re\\\\x13as\")\n","            arima_res = x13_arima_analysis(endog = orig_series, maxorder = (2, 2), maxdiff = (1, 1), \n","                                           x12path = X13PATH)\n","\n","            # replace the original series with the adjusted variable\n","            data[var].iloc[start:end +1] = arima_res.seasadj\n","            \n","            # reset the currently working directory\n","            os.chdir(\"/content/drive/MyDrive/Colab Notebooks/gdp_re\")\n","        else:\n","            pass\n","    \n","    \n","    return data"],"metadata":{"id":"UldpPas0kSP0","executionInfo":{"status":"ok","timestamp":1658908187596,"user_tz":-540,"elapsed":638,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":153,"outputs":[]},{"cell_type":"code","source":["# a function that calculates the optimal number of factors through PCA: Kaiser Criterion\n","\n","def get_factor_num(data):\n","    \n","    pc = PCA(data, standardize = False, missing = 'drop-row')\n","    ev = pc.eigenvals\n","    num_factor = np.sum([ev >= 1.0])\n","    \n","    return num_factor"],"metadata":{"id":"iZ3WwK69kSE2","executionInfo":{"status":"ok","timestamp":1658909044991,"user_tz":-540,"elapsed":2,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":193,"outputs":[]},{"cell_type":"code","source":["# a function which returns the best AR model\n","\n","def ar_model(y):               \n","        sel = ar_select_order(y, 12, old_names=False)\n","        res = sel.model.fit() \n","        return res \n"],"metadata":{"id":"_seTYYVCkRv2","executionInfo":{"status":"ok","timestamp":1658909045736,"user_tz":-540,"elapsed":2,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":194,"outputs":[]},{"cell_type":"code","source":["# a function which fills missing values with a dynamic factor model\n","# This model accounts for the complex structure of factor loadings: \n","#`dic` arguments must be provided to classify each variable into a certain group that shares the same factor.\n","# In this model, one global factor, which influences all variables, is assumed. \n","\n","def df_model(data, dic, num_factor):\n","    \n","    cwd = os.getcwd()\n","    os.chdir(cwd)\n","    var_list = pd.read_csv('VarList_20220703_NABO.csv')\n","    \n","    num_q = (var_list['FREQ'] == 'Q').sum() # the number of quarterly variables\n","    \n","    varname_set = data.columns\n","    varname_set_q = varname_set[ : num_q].to_list()\n","    \n","    endog_q = data[varname_set_q].resample('Q').last()\n","    endog_q = endog_q.astype(float)\n","    \n","    #endog  = data.iloc[ :, num_q : ]\n","    \n","    endog  = data\n","\n","    # factor-loadings structure: \n","    \n","    my_factors = {}\n","    \n","    for i in varname_set:\n","        if dic[i]['GROUP'] != 'NOMINAL':\n","            my_factors[i] = ['GLOBAL', dic[i]['GROUP']]\n","        else:\n","            my_factors[i] = ['GLOBAL']\n","    \n","    #my_factors = {i:['GLOBAL', dic[i]['GROUP']] for i in varname_set}\n","    \n","    # setting up the Dynamic Factor Model\n","    \n","   # model = sm.tsa.DynamicFactorMQ(endog, endog_quarterly = endog_q, factors = num_factor, idiosyncratic_ar1 = True)\n","    \n","    model = sm.tsa.DynamicFactorMQ(endog, factors = num_factor, idiosyncratic_ar1 = True)\n","    \n","    # model = sm.tsa.DynamicFactorMQ(endog, endog_quarterly = endog_q)\n","    \n","    return model"],"metadata":{"id":"gSV3znbRkRpF","executionInfo":{"status":"ok","timestamp":1658910307522,"user_tz":-540,"elapsed":780,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":216,"outputs":[]},{"cell_type":"code","source":["# function which replace the missing values with the DFM\n","\n","\n","def fill_missing(data, dic):\n","    \n","    # NaN Check matrix:\n","    null_check = data.isnull() \n","    \n","    # sets the opitmal number of factors in the data\n","    \n","    new_data = copy.deepcopy(data)\n","    \n","    print('Finding the optimal number of factor starts.')\n","    num_factor = get_factor_num(new_data)\n","    print('Finding the optimal number of factor ends.')\n","    \n","    # fits the DFM model\n","    \n","    my_df_model = df_model(data, dic, num_factor)\n","    res = my_df_model.fit()  \n","    dfm_forecasts = res.get_prediction(start = data.index[0], end = data.index[-1], information_set = 'smoothed')\n","        \n","    # replace missing values with forecasted values generated from the DFM model                                  \n","    \n","    null_check_binary = null_check.astype(int)\n","    filled_data = (1-null_check_binary).mul(np.nan_to_num(data))+(null_check_binary).mul(dfm_forecasts.predicted_mean)\n","    \n","    \n","    filled_data = filled_data[data.columns.to_list()]  \n","    \n","    return filled_data         "],"metadata":{"id":"H7WcBVVqlilN","executionInfo":{"status":"ok","timestamp":1658910307523,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":217,"outputs":[]},{"cell_type":"code","source":["\n","# a function which gets currently available informaton: \n","# note: this function should be used when no forecasts are made on the missing values in the original dataset\n","\n","def get_current_avail_x(data):\n","    \n","    X = data.iloc[:, 1:]\n","    col_names = X.columns\n","    \n","    new_x = np.zeros(X.shape[1])\n","    null_check = X.isnull() \n","    \n","    \n","    for i in range(len(col_names)):\n","\n","        idx = null_check[col_names[i]].index[null_check[col_names[i]] == False]\n","        end = np.where(X.index == idx[-1])[0][0]\n","        value = X[col_names[i]].iloc[end]\n","        new_x[i] = value\n","    \n","    return new_x   "],"metadata":{"id":"bec1MtL6lieC","executionInfo":{"status":"ok","timestamp":1658910307523,"user_tz":-540,"elapsed":3,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":218,"outputs":[]},{"cell_type":"code","source":["# gets the network training\n","\n","def train_network(X, y, lookback, mask_num):    \n","    \n","    seed_num = 1234\n","    np.random.seed(seed_num)\n","    rn.seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    \n","    \n","\n","    model = keras.Sequential()\n","    model.add(keras.layers.InputLayer(input_shape= (lookback, X.shape[2])))\n","    model.add(keras.layers.Masking(mask_value= mask_num))\n","    model.add(keras.layers.LSTM(10, activation= 'sigmoid', return_sequences = False, \n","                                kernel_regularizer = 'l1_l2', recurrent_regularizer = 'l1_l2'))        \n","    model.add(keras.layers.Dense(1))\n","    \n","    \n","#     inputs = keras.Input(shape=(lookback, X.shape[2]), dtype='float32')\n","#     masked = keras.layers.Masking(mask_value = mask_num)(inputs)\n","#     lstm = keras.layers.LSTM(300, activation='sigmoid')(masked)\n","#     output = keras.layers.Dense(1)(lstm)\n","#     model = keras.models.Model(inputs, output)\n","    \n","    opt = keras.optimizers.SGD(learning_rate= 0.01)\n","    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 100, restore_best_weights= True)\n","    \n","    model.compile(optimizer = opt, loss = 'mse', metrics =[keras.metrics.RootMeanSquaredError()])\n","    model.fit(X,y, batch_size = 32, epochs = 2000, validation_split = 0.25, callbacks = [stop_early])\n","    return model\n"],"metadata":{"id":"FlDNKd7LliXQ","executionInfo":{"status":"ok","timestamp":1658910307524,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":219,"outputs":[]},{"cell_type":"code","source":["\n","# a function which yields new instance of X at the foreascasting point\n","# this is an original function\n","\n","def get_new_instance(start_m, end_m, lookback, dic, mask_num, step):\n","    \n","    data, dic = get_vintage_data(start_m, end_m)\n","    \n","    gdp_idx = data[data.iloc[:, 1].notnull()].index.tolist() # the list of index where gdp data is not null\n","    end_idx = data.index[-1] # end index of vintage dataset\n","    \n","    # determine the length of monthly forecasts\n","    \n","    if (end_idx.month == 1) | (end_idx.month == 4) | (end_idx.month == 7) | (end_idx.month == 10):\n","        \n","        period = pd.period_range(start = end_idx + 1, end = end_idx + 2 + 3*step, freq = 'M')\n","        \n","        # create NaN rows up to the end of the quarter\n","        for m in period:\n","            data = data.append(pd.Series(name = m)) \n","    \n","    elif (end_idx.month == 2) | (end_idx.month == 5) | (end_idx.month == 8) | (end_idx.month == 11):\n","        \n","        period = pd.period_range(start = end_idx + 1, end = end_idx + 1 + 3*step, freq = 'M')\n","        \n","        # create NaN rows up to the end of the quarter\n","        for m in period:\n","            data = data.append(pd.Series(name = m)) \n","    \n","    else:\n","        \n","        if step == 0:\n","            pass\n","        else:\n","            period = pd.period_range(start = end_idx + 1, end = end_idx + 3*step, freq = 'M')\n","            # create NaN rows up to the end of the quarter\n","            for m in period:\n","                data = data.append(pd.Series(name = m)) \n","    \n","    \n","    # filling the missing values through DFM: \n","    \n","    dataX = data.iloc[:, 1:]\n","    \n","    tr_data = transform(dataX, dic)\n","    filled_data = fill_missing(tr_data, dic)\n","      \n","    #filled_data.iloc[:, 1:4].loc[filled_data.iloc[:, 1:4].index > gdp_idx[-1]] = np.nan  # making unobserved gdp nan value\n","    \n","    \n","    scaler = StandardScaler()\n","    scaler.fit(filled_data)\n","    X = scaler.transform(filled_data)\n","    \n","#    X = X.to_numpy()\n","    \n","    new_X = create_lookback_data(X, lookback)\n","    new_X = np.array(new_X)\n","    new_inst = new_X[-1]\n","    \n","#     arr = []\n","    \n","#     for i in range(new_inst.shape[0]):\n","#         item = new_inst[i]\n","#         item = item[~np.isnan(item)]\n","#         arr.append(item)\n","\n","#     arr = np.array(arr)\n","#     final_input = keras.preprocessing.sequence.pad_sequences(arr, maxlen = filled_data.shape[1], \n","#                                                              padding ='pre', dtype = float, value = mask_num)\n","    \n","    return new_inst\n","\n"],"metadata":{"id":"ocUi4ThvraNt","executionInfo":{"status":"ok","timestamp":1658910308287,"user_tz":-540,"elapsed":3,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":220,"outputs":[]},{"cell_type":"code","source":["\n","# looked backed dataset: a function which returns lookback dataset and target variable\n","\n","def get_training_data(data, target, lookback):\n","       \n","    X = []\n","    y = []\n","    \n","    for i in range(len(data)-lookback-1):\n","        t = []\n","        for j in range(1,lookback+1):\n","            # Gather past records upto the lookback period\n","            t.append(data[(i+j+1)])\n","        \n","        X.append(t)\n","        \n","        y.append(target[i+lookback+1])    \n","    \n","    return X, y"],"metadata":{"id":"KDYsM2rzliQX","executionInfo":{"status":"ok","timestamp":1658910308288,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":221,"outputs":[]},{"cell_type":"code","source":["# create loolback dataset excep target variable\n","\n","def create_lookback_data(data, lookback):\n","    \n","    X = []\n","    \n","    for i in range(len(data)-lookback-1):\n","        t = []\n","        for j in range(1,lookback+1):\n","            # Gather past records upto the lookback period\n","            t.append(data[(i+j+1)])\n","        \n","        X.append(t)\n","    return X\n"],"metadata":{"id":"i4LtFir0liJC","executionInfo":{"status":"ok","timestamp":1658910308288,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":222,"outputs":[]},{"cell_type":"code","source":["\n","# state = 0 : first month\n","# state =1  : middle month\n","# state = 2: end month\n","# state = 3: all month\n","\n","\n","def gen_state_var(simul_data):\n","    \n","    simul_data['STATE'] = np.nan\n","    \n","    simul_data['STATE'].loc[(simul_data.index.month == 1) | (simul_data.index.month == 4) \n","                   | (simul_data.index.month == 7) | (simul_data.index.month == 10)] = 0\n","      \n","    simul_data['STATE'].loc[(simul_data.index.month == 2) | (simul_data.index.month == 5) \n","                   | (simul_data.index.month == 8) | (simul_data.index.month == 11)] = 1\n","    \n","    \n","    simul_data['STATE'].loc[(simul_data.index.month == 3) | (simul_data.index.month == 6) \n","                   | (simul_data.index.month == 9) | (simul_data.index.month == 12)] = 2\n","    \n","    simul_data['STATE'] = simul_data['STATE'].astype(int)\n","    \n","    return simul_data\n"],"metadata":{"id":"sp5C5zxQliBu","executionInfo":{"status":"ok","timestamp":1658910308288,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":223,"outputs":[]},{"cell_type":"code","source":["\n","\n","# compute RMSE metric\n","# 'start', end' must be in the form of 'y-m'. For example, '2015-01'\n","# state = 0 : first month\n","# state =1  : middle month\n","# state = 2: end month\n","# state = 3: all month\n","\n","def rmse_cal(simul_data, start, end, state):\n","    \n","    data = gen_state_var(simul_data)\n","    \n","    if state != 3:\n","        data = data[data['STATE'] == state]\n","    else:\n","        pass\n","\n","    data = data[(data.index <= end) & (data.index >= start) ]\n","    data = data.astype(float)\n","    \n","    fe = data['actual_y'] - data['forecasts'] # forecasting error\n","    fe2 = fe**2 # squared forecasting error\n","    val_rmse = np.sqrt(np.mean(fe2))\n","    \n","    return val_rmse\n","    \n","\n","# compute MAE metric  \n","\n","def mae_cal(simul_data, start, end, state):\n","\n","    data = gen_state_var(simul_data)\n","    \n","    if state != 3:\n","        data = data[data['STATE'] == state]\n","    else:\n","        pass\n"," \n","    data = data[(data.index <= end) & (data.index >= start) ]\n","    data = data.astype(float)\n","    \n","    fe = data['actual_y']- data['forecasts'] # forecasting error\n","    fe_abs = np.absolute(fe) # absolute values of forecasting error\n","    val_mae = np.mean(fe_abs)\n","    \n","    return val_mae"],"metadata":{"id":"fp5j4uVWlh30","executionInfo":{"status":"ok","timestamp":1658910309556,"user_tz":-540,"elapsed":5,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":224,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KrHEx7r6kREX","executionInfo":{"status":"ok","timestamp":1658910309557,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":224,"outputs":[]},{"cell_type":"code","source":["def do_forecast_ex(start_q, end_q, start_m, end_m, start_m_training, key, lookback, IsRecursive): #'@step'\n","    \n","    start_q = start_q # starting quarter of the whole sample \n","    end_q = end_q   # ending quarter of the whole sample\n","    key = key\n","\n","    simul_data = get_actual_gdp_growth(key, start_q, end_q)\n","    simul_data.columns = ['actual_y']\n","    # simul_data.columns = ['actual_y', 'actual_y1', 'actual_y2', 'actual_y3']\n","    simul_data['forecasts'] = np.nan\n","\n","\n","    df_pre = simul_data[simul_data.index < start_m] \n","    window = len(df_pre)\n","\n","\n","    df_post = simul_data[simul_data.index >= start_m]\n","    forecast_horizon = len(df_post)\n","\n","\n","    # out-of-sample period\n","    period = pd.period_range(start = start_m, end = end_m, freq = 'M')\n","\n","    # training sample starting point\n","    start_index  = pd.Period(start_m_training, freq = 'M')\n","\n","    start_time = datetime.datetime.now()\n","\n","    for i in period:\n","\n","        end_index = start_index + window\n","\n","        start_m = str(start_index).replace('-', '')\n","        end_m = str(end_index).replace('-', '')\n","\n","        # gets the vintage data at the forecasting time\n","        vintage_data, dic = get_vintage_data(start_m, end_m)\n","\n","        idx = vintage_data[vintage_data['GDP'].notnull()].index.tolist() # index where gdp growth data is not null.\n","\n","        y = vintage_data['GDP'] \n","\n","        dataX = vintage_data.iloc[:, 1:]\n","\n","\n","        # transforming the raw data and filling the missing values\n","\n","        # print(f'[{dt.datetime.now()}]: Transforming the original data starts.')\n","        tr_data = transform(dataX, dic)\n","        # print(f'[{dt.datetime.now()}]: Transforming the original data ends.')\n","\n","        # print(f'[{dt.datetime.now()}]: Filling the missing values starts.')\n","        filled_data = fill_missing(tr_data, dic)\n","        # print(f'[{dt.datetime.now()}]: Filling the missing values ends.')\n","\n","\n","    #     X = filled_data[filled_data.index <= idx[-1]] # features data\n","\n","    #     scaler = StandardScaler()\n","    #     scaler.fit(X)\n","    #     X = scaler.transform(X)\n","\n","\n","    # #    X = X.to_numpy() # this need to be deleted when MinMaxScaler is used.\n","\n","\n","    #     y = y[y.index <= idx[-1]]\n","\n","\n","    #     # generate the lookbacked train data set with the corresponding label at the quarterly frequency:\n","        \n","    #     lookback = int(lookback)\n","        # mask_num = 0\n","\n","\n","        # train_X, train_y = get_training_data(X, y, lookback)\n","        # train_X = train_X[-1::-3] # this is for quarterly filtering\n","        # train_y = train_y[-1::-3] # this is for quarterly filtering\n","        # train_X = train_X[::-1] # reverse the sequence\n","        # train_y = train_y[::-1] # reverse the sequence\n","\n","        # train_X = np.array(train_X)\n","        # train_X = train_X.reshape(train_X.shape[0], lookback, train_X.shape[2])\n","\n","        # train_y = np.array(train_y)\n","        # train_y = train_y.reshape(train_y.shape[0], 1)\n","\n","        # # gets the trained neural network with given data\n","\n","        # print(f'[{dt.datetime.now()}]: Learning starts.')"],"metadata":{"id":"iXpnEeO8cL43","executionInfo":{"status":"ok","timestamp":1658910309557,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":225,"outputs":[]},{"cell_type":"code","source":["def train_network(X, y, lookback, mask_num):    \n","    \n","    seed_num = 1234\n","    np.random.seed(seed_num)\n","    rn.seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    \n","    \n","\n","    model = keras.Sequential()\n","    model.add(keras.layers.InputLayer(input_shape= (lookback, X.shape[2])))\n","    model.add(keras.layers.Masking(mask_value= mask_num))\n","    model.add(keras.layers.LSTM(10, activation= 'sigmoid', return_sequences = False, \n","                                kernel_regularizer = 'l1_l2', recurrent_regularizer = 'l1_l2'))        \n","    model.add(keras.layers.Dense(1))\n","    \n","    \n","#     inputs = keras.Input(shape=(lookback, X.shape[2]), dtype='float32')\n","#     masked = keras.layers.Masking(mask_value = mask_num)(inputs)\n","#     lstm = keras.layers.LSTM(300, activation='sigmoid')(masked)\n","#     output = keras.layers.Dense(1)(lstm)\n","#     model = keras.models.Model(inputs, output)\n","    \n","    opt = keras.optimizers.SGD(learning_rate= 0.01)\n","    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 100, restore_best_weights= True)\n","    \n","    model.compile(optimizer = opt, loss = 'mse', metrics =[keras.metrics.RootMeanSquaredError()])\n","    model.fit(X,y, batch_size = 32, epochs = 2000, validation_split = 0.25, callbacks = [stop_early])\n","    return model"],"metadata":{"id":"K0hKh0F5ZKrF","executionInfo":{"status":"ok","timestamp":1658910309557,"user_tz":-540,"elapsed":3,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":226,"outputs":[]},{"cell_type":"code","source":["start_q = '2001Q1' # whole sample starting point\n","end_q = '2021Q4'   # whole sample ending point\n","key = '7MJBDXDXI03KBLP71JFE'\n","start_m = '201501'\n","end_m = '202112'\n","start_m_training = '200101'\n","lookback = 10\n","IsRecursive = 1\n","\n","forecasted_data = do_forecast_ex(start_q, end_q, start_m, end_m, start_m_training, key, lookback, IsRecursive)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"id":"D8P9AbQrmI6T","executionInfo":{"status":"error","timestamp":1658910311858,"user_tz":-540,"elapsed":1758,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"a6f1d756-8d3b-4364-9d5f-beaa3b048a57"},"execution_count":227,"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-07-27 08:25:11.417538]: Url Request Success\n","Finding the optimal number of factor starts.\n","Finding the optimal number of factor ends.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-227-2917f0c18773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mIsRecursive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mforecasted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_forecast_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_m_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsRecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-225-dad1a1ec2f8d>\u001b[0m in \u001b[0;36mdo_forecast_ex\u001b[0;34m(start_q, end_q, start_m, end_m, start_m_training, key, lookback, IsRecursive)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# print(f'[{dt.datetime.now()}]: Filling the missing values starts.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mfilled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# print(f'[{dt.datetime.now()}]: Filling the missing values ends.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-217-dc3b59ce56c3>\u001b[0m in \u001b[0;36mfill_missing\u001b[0;34m(data, dic)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# fits the DFM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmy_df_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_df_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdfm_forecasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'smoothed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-216-4b79a183b940>\u001b[0m in \u001b[0;36mdf_model\u001b[0;34m(data, dic, num_factor)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# model = sm.tsa.DynamicFactorMQ(endog, factors = num_factor, idiosyncratic_ar1 = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDynamicFactorMQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog_quarterly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendog_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.tsa.api' has no attribute 'DynamicFactorMQ'"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"KcD4_8cGqqaq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","model = sm.tsa.DynamicFactorMQ()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194},"id":"oN9_YmDTqqPL","executionInfo":{"status":"error","timestamp":1658909787261,"user_tz":-540,"elapsed":566,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"e9c103ae-3f3e-427f-c5ad-d6b72da23b43"},"execution_count":213,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-213-7620d7e822d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDynamicFactorMQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.tsa.api' has no attribute 'DynamicFactorMQ'"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"LBPIQde7qqGE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_APp9bHAqp9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sjjFyc1CqpzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XIBd1sx-qpLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjXj9FCiKniL","executionInfo":{"status":"ok","timestamp":1658908747547,"user_tz":-540,"elapsed":49,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"6d3527ae-48a3-40e1-9818-db1360999e1e"},"execution_count":179,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_5 (Embedding)     (None, None, 1)           48        \n","                                                                 \n"," lstm_20 (LSTM)              (None, None, 234)         220896    \n","                                                                 \n"," dropout_20 (Dropout)        (None, None, 234)         0         \n","                                                                 \n"," lstm_21 (LSTM)              (None, None, 117)         164736    \n","                                                                 \n"," dropout_21 (Dropout)        (None, None, 117)         0         \n","                                                                 \n"," lstm_22 (LSTM)              (None, None, 78)          61152     \n","                                                                 \n"," dropout_22 (Dropout)        (None, None, 78)          0         \n","                                                                 \n"," lstm_23 (LSTM)              (None, 10)                3560      \n","                                                                 \n"," dropout_23 (Dropout)        (None, 10)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 450,403\n","Trainable params: 450,403\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0qHflI7O1qi","executionInfo":{"status":"ok","timestamp":1658902204253,"user_tz":-540,"elapsed":824,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"70b0ef11-fa7e-4472-a265-edb623aea6e8"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<keras.layers.embeddings.Embedding at 0x7f8bd02e7f90>,\n"," <keras.layers.recurrent_v2.LSTM at 0x7f8bcdcdd210>,\n"," <keras.layers.core.dropout.Dropout at 0x7f8bd03a3dd0>,\n"," <keras.layers.recurrent_v2.LSTM at 0x7f8bd03858d0>,\n"," <keras.layers.core.dropout.Dropout at 0x7f8bcd943f50>,\n"," <keras.layers.recurrent_v2.LSTM at 0x7f8bcdbc5150>,\n"," <keras.layers.core.dropout.Dropout at 0x7f8bcddb4250>,\n"," <keras.layers.recurrent_v2.LSTM at 0x7f8bcddab890>,\n"," <keras.layers.core.dropout.Dropout at 0x7f8bd031af10>,\n"," <keras.layers.core.dense.Dense at 0x7f8bcdf89dd0>]"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["names = [weight.name for layer in model.layers for weight in layer.weights]\n","weights = model.get_weights()\n","\n","# suppress scientific notation\n","np.set_printoptions(suppress=True) #If True, always print floating point numbers using fixed point notation\n","for name, weight in zip(names, weights):\n","    if name == 'embedding_3/embeddings:0': #@@\n","        kernel_0 = weight\n","    if name == 'lstm_12/lstm_cell_12/kernel:0':\n","        recurrent_kernel_0 = weight\n","    if name == 'lstm_12/lstm_cell_12/recurrent_kernel:0':\n","        bias_0 = weight\n","    if name == 'lstm_12/lstm_cell_12/bias:0':\n","        bias_0 = weight\n","\n","        \n","\n","    elif name == '@':\n","        output = weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138},"id":"IRNTVkJ5I43A","executionInfo":{"status":"error","timestamp":1658903519246,"user_tz":-540,"elapsed":589,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"b0bc9671-e966-467c-9e8b-53782b040106"},"execution_count":107,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-107-b4ac7a09a077>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    f name == 'lstm_12/lstm_cell_12/recurrent_kernel:0':\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tl8L4zttQOYD","executionInfo":{"status":"ok","timestamp":1658903242267,"user_tz":-540,"elapsed":843,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"85181ca8-d3f2-490f-90a0-0a6964e99667"},"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eASkiXc2JUS3","executionInfo":{"status":"ok","timestamp":1658900064751,"user_tz":-540,"elapsed":529,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"5cdfdc81-d824-4925-f274-7867fca762ce"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['embedding_3/embeddings:0',\n"," 'lstm_12/lstm_cell_12/kernel:0',\n"," 'lstm_12/lstm_cell_12/recurrent_kernel:0',\n"," 'lstm_12/lstm_cell_12/bias:0',\n"," 'lstm_13/lstm_cell_13/kernel:0',\n"," 'lstm_13/lstm_cell_13/recurrent_kernel:0',\n"," 'lstm_13/lstm_cell_13/bias:0',\n"," 'lstm_14/lstm_cell_14/kernel:0',\n"," 'lstm_14/lstm_cell_14/recurrent_kernel:0',\n"," 'lstm_14/lstm_cell_14/bias:0',\n"," 'lstm_15/lstm_cell_15/kernel:0',\n"," 'lstm_15/lstm_cell_15/recurrent_kernel:0',\n"," 'lstm_15/lstm_cell_15/bias:0',\n"," 'dense_3/kernel:0',\n"," 'dense_3/bias:0']"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["len(model.layers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hi9RPE9TGz1d","executionInfo":{"status":"ok","timestamp":1658899672961,"user_tz":-540,"elapsed":978,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"bc675448-346d-412f-9fe7-7c03ad1b5ac9"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["def get_layer_output(layer_name, data):\n","    intermediate_layer_model = keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n","    \n","    return intermediate_layer_model.predict(data)  "],"metadata":{"id":"gCf51cXrDXA1","executionInfo":{"status":"ok","timestamp":1658899259704,"user_tz":-540,"elapsed":1118,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["outputs = {}\n","for layer in model.layers :\n","    outputs[layer.name] = get_layer_output(layer.name, X_train.iloc[0])\n","    print(layer.name, outputs[layer.name].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63aDLnCAGuEn","executionInfo":{"status":"ok","timestamp":1658899629889,"user_tz":-540,"elapsed":9880,"user":{"displayName":"김다은","userId":"16190703000834159129"}},"outputId":"92f58c21-9bee-463c-8bc4-616709a43095"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["embedding_3 (48, 1, 1)\n","lstm_12 (48, 1, 234)\n","dropout_12 (48, 1, 234)\n","lstm_13 (48, 1, 117)\n","WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8bdfc4db00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8bdfc4db00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["dropout_13 (48, 1, 117)\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8bdeb44cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8bdeb44cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["lstm_14 (48, 1, 78)\n","dropout_14 (48, 1, 78)\n","lstm_15 (48, 10)\n","dropout_15 (48, 10)\n","dense_3 (48, 1)\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"y6KTxbfIisRr","executionInfo":{"status":"ok","timestamp":1658898430728,"user_tz":-540,"elapsed":4,"user":{"displayName":"김다은","userId":"16190703000834159129"}}},"outputs":[],"source":["def get_relavance(target_data, target_class) :\n","    e = get_layer_output('embedding_1', target_data).squeeze()\n","    \n","    #forword\n","    T = maxlen\n","    d = int(256/4)  # hidden units\n","\n","    idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n","    idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n","\n","    h  = np.zeros((T,d))\n","    c  = np.zeros((T,d))\n","\n","    gates_xh  = np.zeros((T, 4*d))  \n","    gates_hh  = np.zeros((T, 4*d)) \n","    gates_pre = np.zeros((T, 4*d))  \n","    gates     = np.zeros((T, 4*d))  \n","\n","    for t in range(T):\n","        gates_xh[t]     = np.dot(e[t], kernel_0)\n","        gates_hh[t]     = np.dot(h[t-1],recurrent_kernel_0)\n","        gates_pre[t]    = gates_xh[t] + gates_hh[t] + bias_0\n","        gates[t, idx]    = 1.0/(1.0 + np.exp(- gates_pre[t,idx]))\n","        gates[t,idx_g]  = np.tanh(gates_pre[t,idx_g]) \n","        c[t]            = gates[t,idx_f]*c[t-1] + gates[t,idx_i]*gates[t,idx_g]\n","        h[t]            = gates[t,idx_o]*np.tanh(c[t])\n","\n","    score = np.dot(h[t], output)    \n","    \n","    #backword\n","\n","    C      = output.shape[1] # number of classes\n","    dx     = np.zeros(e.shape)\n","\n","    dh          = np.zeros((T, d))\n","    dc          = np.zeros((T, d))\n","    dgates_pre  = np.zeros((T, 4*d))  # gates pre-activation\n","    dgates      = np.zeros((T, 4*d))  # gates activation\n","\n","    ds                    = np.zeros((C))\n","    ds[target_class] = 1.0\n","    dy               = ds.copy()\n","\n","    #맨처음을 0으로 시작하지 않게 위한조치\n","    dh[T-1]     = np.dot(dy, output.T)\n","\n","    for t in reversed(range(T)): \n","        dgates[t,idx_o]    = dh[t] * np.tanh(c[t])  # do[t]\n","        dc[t]             += dh[t] * gates[t,idx_o] * (1.-(np.tanh(c[t]))**2) # dc[t]\n","        dgates[t,idx_f]    = dc[t] * c[t-1]         # df[t]\n","        dc[t-1]            = dc[t] * gates[t,idx_f] # dc[t-1]\n","        dgates[t,idx_i]    = dc[t] * gates[t,idx_g] # di[t]\n","        dgates[t,idx_g]    = dc[t] * gates[t,idx_i] # dg[t]\n","        dgates_pre[t,idx]  = dgates[t,idx] * gates[t,idx] * (1.0 - gates[t,idx]) # d ifo pre[t]\n","        dgates_pre[t,idx_g]= dgates[t,idx_g] *  (1.-(gates[t,idx_g])**2) # d g pre[t]\n","        dh[t-1]            = np.dot(dgates_pre[t], recurrent_kernel_0.T)\n","        dx[t]           = np.dot(dgates_pre[t], kernel_0.T)\n","    \n","    return score, dx"]},{"cell_type":"code","source":[""],"metadata":{"id":"t74BvLcxDTej"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"LPR.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}
